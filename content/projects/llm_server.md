---
title: Large Lenguage Server App
date: 2025-04-25
github: https://github.com/13Mai13/llm-server
tags:
    - Project
    - LLM
    - Python
    - Service
    - Inference
    - Optimization
---

A high-performance LLM inference server with structured and unstructured output validation, designed for distributed systems and optimized for large-scale LLM operations. Is optimized for high throughput low latency. 

The core components of the project are: 

* Connection pool

* Batching startegies

* Structured vs unstructured output generation (can check the results [here](https://github.com/13Mai13/llm-server/blob/main/docs/DEEP_DIVE.md#key-findings))